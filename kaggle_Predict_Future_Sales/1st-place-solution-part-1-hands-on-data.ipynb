{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc, warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8d38035771ffce7adad33b76d387a533b717c893"
   },
   "source": [
    "# 概要\n",
    "\n",
    "このカーネルはどんなものですか？\n",
    "\n",
    "予測することはありません\n",
    "作成する機能はありません\n",
    "競技データを読み込み、詳しく調べてみます。私たちが手にしているものを理解し、それをどのように扱うことができるかを考えてみます。\n",
    "\n",
    "* * *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0701d6cc1333560ed55d1cfe2308d7494921b6e2"
   },
   "source": [
    " ## Load train data\n",
    " * * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "a0a1bff7d00c5a4f8f7903d2655aa25d17406e9e"
   },
   "outputs": [],
   "source": [
    "sale_train = pd.read_csv('../input/sales_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c16019f841e617154a71d6fab73eb116c2690082"
   },
   "source": [
    "We can view basic DafaFrame information. \n",
    "\n",
    "As you can see, we do not have broken and nan data that is good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c9c35b30b6b027f5f5730e070afc2cb21a92bf2e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"----------Top-5- Record----------\")\n",
    "print(sale_train.head(5))\n",
    "print(\"-----------Information-----------\")\n",
    "print(sale_train.info())\n",
    "print(\"-----------Data Types-----------\")\n",
    "print(sale_train.dtypes)\n",
    "print(\"----------Missing value-----------\")\n",
    "print(sale_train.isnull().sum())\n",
    "print(\"----------Null value-----------\")\n",
    "print(sale_train.isna().sum())\n",
    "print(\"----------Shape of Data----------\")\n",
    "print(sale_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0c3f9b62c0ae87d1ae99af6bf62b38e8ed167b30"
   },
   "source": [
    "行が重複していますが、間違いではないと思います。\n",
    "\n",
    "販売方法やクライアントの種類などが違うのかもしれません。\n",
    "\n",
    "削除することはできますが、3mの6列で違いが出るとは本当に思えません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": false,
    "_uuid": "d2800fe80ac4003ef9a66c5e37eaf6fb92b4aa4f"
   },
   "outputs": [],
   "source": [
    "print('Number of duplicates:', len(sale_train[sale_train.duplicated()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f55dbe8feb5c2ecf5cc40a3d592ddd5b48ea201d"
   },
   "source": [
    "私はデータフレームのダウンキャストをお勧めします。メモリの節約になりますが、信じられないことに、可能な限りのメモリが必要になります。\n",
    "\n",
    "私たちの場合、134.4+MBから61.6+MBになりました。\n",
    "\n",
    "今はまだ大したことはありませんが、このようなアプローチはより大きなDFにも有効です。\n",
    "\n",
    "より多くのヒントについては、以下の2つのリンクを参照してください（私はanqituからそのダウンキャストの基本的なスニペットを盗んだ））。\n",
    "\n",
    "https://www.kaggle.com/anqitu/feature-engineer-and-model-ensemble-top-10   \n",
    "https://www.kaggle.com/yuliagm/how-to-work-with-big-datasets-on-16g-ram-dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "86b8ccd49688e11eba077c21aa638c759a10a176",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def downcast_dtypes(df):\n",
    "    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
    "    int_cols = [c for c in df if df[c].dtype in [\"int64\", \"int32\"]]\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[int_cols] = df[int_cols].astype(np.int16)\n",
    "    return df\n",
    "\n",
    "sale_train = downcast_dtypes(sale_train)\n",
    "print(sale_train.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b95a8f4ca9e94d5260aa578efd3d410fc8bc468d"
   },
   "source": [
    "## 1.1 Item_id\n",
    "* * *\n",
    "### Lets group data by item_id and date_block_num and look closer on it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "sales_by_item_id = sale_train.pivot_table(index=['item_id'],values=['item_cnt_day'], \n",
    "                                        columns='date_block_num', aggfunc=np.sum, fill_value=0).reset_index()\n",
    "sales_by_item_id.columns = sales_by_item_id.columns.droplevel().map(str)\n",
    "sales_by_item_id = sales_by_item_id.reset_index(drop=True).rename_axis(None, axis=1)\n",
    "sales_by_item_id.columns.values[0] = 'item_id'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bb9510bf9c352a073fdcda40ec50d7dc402828ef"
   },
   "source": [
    "### シンプルなグラフ\n",
    "\n",
    "このグラフからわかること。基本的には何もありません。)) 電車のデータには古い製品が多く（劣化線）、1Cの製品には季節性があり、おそらく発売日に依存していることがわかるだけです。\n",
    "\n",
    "私はグラフやプレゼンテーションがあまり得意ではないので、もっと良いデータ表現の例があると思います。\n",
    "\n",
    "https://www.kaggle.com/dimitreoliveira/model-stacking-feature-engineering-and-eda  \n",
    "https://www.kaggle.com/jagangupta/time-series-basics-exploring-traditional-ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f41fa75f4089861ffdfdc7ee551f2d99e0d7f1ac",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sales_by_item_id.sum()[1:].plot(legend=True, label=\"Monthly sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "183eeb505320b71e99ef429bf48324ea1d74cb90"
   },
   "outputs": [],
   "source": [
    "sales_by_item_id.mean()[1:].plot(legend=True, label=\"Monthly mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bf5109a824d10570f1ba3eef89be7ce3759738be"
   },
   "source": [
    "### 時代遅れ（過去6ヶ月間販売実績なし）の商品がどれだけあるか見てみましょう。\n",
    "\n",
    "21807件のうち12391件は膨大な数です。おそらく、すべてのアイテムに0を設定して、モデル予測を行わないことができるでしょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "69d3323d9cfcd63a11b0448fa716250ee5e51e59",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outdated_items = sales_by_item_id[sales_by_item_id.loc[:,'27':].sum(axis=1)==0]\n",
    "print('Outdated items:', len(outdated_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "85ff60f16dde4356ea135bc7e0572c6a335253e7"
   },
   "source": [
    "### How many outdated items in test set?\n",
    "6888 - not much but we have such items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "32886b44ba7c8fab632a1d10d9aa990f7886e8f9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('../input/test.csv')\n",
    "print('Outdated items in test set:', len(test[test['item_id'].isin(outdated_items['item_id'])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9c9e24173a4473a1cb523c054d2999558eac9d2c"
   },
   "source": [
    "### 価格と販売台数による異常値\n",
    "\n",
    "これらは後で除去します\n",
    "\n",
    "####Denis Larionov氏が作成した美しいカーネルをご覧ください（私はそこからいくつかのグラフを盗みました\n",
    "\n",
    "https://www.kaggle.com/dlarionov/feature-engineering-xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "972f035270aa822d93db73925fe3868b2c785876"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.xlim(-100, 3000)\n",
    "sns.boxplot(x=sale_train['item_cnt_day'])\n",
    "print('Sale volume outliers:',sale_train['item_id'][sale_train['item_cnt_day']>500].unique())\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.xlim(sale_train['item_price'].min(), sale_train['item_price'].max())\n",
    "sns.boxplot(x=sale_train['item_price'])\n",
    "print('Item price outliers:',sale_train['item_id'][sale_train['item_price']>50000].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "df11bedc80cd9816f60c2883fa6cb4d6bcf6cd1e"
   },
   "source": [
    "### 可能なitem_idの特徴。\n",
    "\n",
    "* ラグ\n",
    "* 発売日\n",
    "* 先月の販売状況\n",
    "* 発売日\n",
    "* 隣人（idが1000と1001のアイテムは、ジャンル、タイプ、発売日などが似ている可能性があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c3ec31c7426de7bb806e0c10c6f7d95e12761d90"
   },
   "source": [
    "## 1.2 shop_id\n",
    "* * *\n",
    "### Lets now group train data by shop_id.\n",
    "We can see new shops - probably there will be a sales spike (opening event for example).\n",
    "Apparently closed shops (ill call it \"outdated shops\")  - no sales for last 6 months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "117e47f7680d6bf6ad4f13e7cb191703b74fa5a2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sales_by_shop_id = sale_train.pivot_table(index=['shop_id'],values=['item_cnt_day'], \n",
    "                                        columns='date_block_num', aggfunc=np.sum, fill_value=0).reset_index()\n",
    "sales_by_shop_id.columns = sales_by_shop_id.columns.droplevel().map(str)\n",
    "sales_by_shop_id = sales_by_shop_id.reset_index(drop=True).rename_axis(None, axis=1)\n",
    "sales_by_shop_id.columns.values[0] = 'shop_id'\n",
    "\n",
    "for i in range(6,34):\n",
    "    print('Not exists in month',i,sales_by_shop_id['shop_id'][sales_by_shop_id.loc[:,'0':str(i)].sum(axis=1)==0].unique())\n",
    "\n",
    "for i in range(6,28):\n",
    "    print('Shop is outdated for month',i,sales_by_shop_id['shop_id'][sales_by_shop_id.loc[:,str(i):].sum(axis=1)==0].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "43d62def13e93719c56bef61263860ad473ef59c"
   },
   "source": [
    "In our test set we have 5100 sales in really new shop and no \"outdated shops\" but anyway it is good feature for future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "33dc0888c1c300114ba6fd18d4f19eea8c4ec2dc"
   },
   "outputs": [],
   "source": [
    "print('Recently opened shop items:', len(test[test['shop_id']==36]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "777c65d11da24810e2f1a6e4c8f69342b7d50c58"
   },
   "source": [
    "### Possible shop_id features\n",
    "1. Lags (shop_id/shp_cnt_mth)\n",
    "2. Opening month (possible  opening sales)\n",
    "3. Closed Month (possible stock elimination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "23feaefb184db48a5768eb8ff278c31abd8128e7"
   },
   "source": [
    "## 1.3 Price\n",
    "* * *\n",
    "### Possible Price features:\n",
    "1. Price category (1$/10$/20$/ etc.) - obviously (or not obviously),  items with smaller price have greater volumes\n",
    "2. Discount and Discount duration\n",
    "3. Price lag (shows discount)\n",
    "4. Price correction (rubl/usd pair)\n",
    "5. Shop Revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9630ea096fa1e19a0889c0855a2d7b16d17c7350"
   },
   "source": [
    "## 1.4 Dates\n",
    "* * *\n",
    "### Possible Date features:\n",
    "1. Weekends and holidays sales (to correct monthly sales)\n",
    "2. Number of days in the month (to correct monthly sales)\n",
    "3. Month number (for seasonal items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a986daadeb23bb218191e130bbdb9dd572615b9f"
   },
   "source": [
    "## 1.5 Shop info\n",
    "* * *\n",
    "The structure of the shop information is evident.\n",
    "### Shop City | Shop type | Shop name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "48b6d9f2dd244468b16c1a5c3a9a082f6fb21db8"
   },
   "outputs": [],
   "source": [
    "shops = pd.read_csv('../input/shops.csv')\n",
    "shops.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "69702cf86fd59b74fca508963c1651177e710b82"
   },
   "source": [
    "With a close look we can find out that some shops have duplicated id/name - probably it changed location (within commercial center), or it has a different type (isle sale point), but I decided to merge it.\n",
    "* 11 => 10\n",
    "* 1  => 58\n",
    "* 0  => 57\n",
    "* 40 => 39\n",
    "\n",
    "I converted train shop_id to shop_id that is in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0dc3a7e13d879b1f1f4a3aa519800ffd256755ba"
   },
   "outputs": [],
   "source": [
    "shops['shop_name'] = shops['shop_name'].apply(lambda x: x.lower()).str.replace('[^\\w\\s]', '').str.replace('\\d+','').str.strip()\n",
    "shops['shop_city'] = shops['shop_name'].str.partition(' ')[0]\n",
    "shops['shop_type'] = shops['shop_name'].apply(lambda x: 'мтрц' if 'мтрц' in x else 'трц' if 'трц' in x else 'трк' if 'трк' in x else 'тц' if 'тц' in x else 'тк' if 'тк' in x else 'NO_DATA')\n",
    "shops.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "81fc1c1fc6a1cbec542fa0b726fa982d2947ace3"
   },
   "source": [
    "### Possible Shop features:\n",
    "1. Shop City\n",
    "2. Shop Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dbc33e1ebf107e1fd5f655f018e2116984dfc0be"
   },
   "source": [
    "## 1.6 Item info\n",
    "* * *\n",
    "Let's see what we can get from this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1ba5be08289a9bf5ff35cb407dd32545b12bf14f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "items = pd.read_csv('../input/items.csv')\n",
    "items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b9d8671932740709147923219fcf0a1e6f280a78"
   },
   "source": [
    "We can enconde \"features\" that many items have.\n",
    "\n",
    "The structure is always the same\n",
    "### Item name [category feature] (additional feature)\n",
    "we can split it, and \"one hot encode it.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "09757b46aa8894f66a8468026d570172d250ae73",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ugly code to show the idea\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "items['name_1'], items['name_2'] = items['item_name'].str.split('[', 1).str\n",
    "items['name_1'], items['name_3'] = items['item_name'].str.split('(', 1).str\n",
    "\n",
    "items['name_2'] = items['name_2'].str.replace('[^A-Za-z0-9А-Яа-я]+', ' ').str.lower()\n",
    "items['name_3'] = items['name_3'].str.replace('[^A-Za-z0-9А-Яа-я]+', ' ').str.lower()\n",
    "items = items.fillna('0')\n",
    "\n",
    "result_1 = Counter(' '.join(items['name_2'].values.tolist()).split(' ')).items()\n",
    "result_1 = sorted(result_1, key=itemgetter(1))\n",
    "result_1 = pd.DataFrame(result_1, columns=['feature', 'count'])\n",
    "result_1 = result_1[(result_1['feature'].str.len() > 1) & (result_1['count'] > 200)]\n",
    "\n",
    "result_2 = Counter(' '.join(items['name_3'].values.tolist()).split(\" \")).items()\n",
    "result_2 = sorted(result_2, key=itemgetter(1))\n",
    "result_2 = pd.DataFrame(result_2, columns=['feature', 'count'])\n",
    "result_2 = result_2[(result_2['feature'].str.len() > 1) & (result_2['count'] > 200)]\n",
    "\n",
    "result = pd.concat([result_1, result_2])\n",
    "result = result.drop_duplicates(subset=['feature'])\n",
    "\n",
    "print('Most common aditional features:', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5269123ec33e0e39a9824e64ae95602883b5c956"
   },
   "source": [
    "### Item name correction\n",
    "For our basic \"name feature\" it is enough to find identical items (not similar but identical),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5701d130b1589300940f588835106561efb248ec"
   },
   "outputs": [],
   "source": [
    "print('Unique item names:', len(items['item_name'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4bf9069a41bc3333150a5eff3bfb6997c5a9d516",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def name_correction(x):\n",
    "    x = x.lower()\n",
    "    x = x.partition('[')[0]\n",
    "    x = x.partition('(')[0]\n",
    "    x = re.sub('[^A-Za-z0-9А-Яа-я]+', ' ', x)\n",
    "    x = x.replace('  ', ' ')\n",
    "    x = x.strip()\n",
    "    return x\n",
    "\n",
    "items['item_name'] = items['item_name'].apply(lambda x: name_correction(x))\n",
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fdab4d126288b29f669807848b6072cab09304c5"
   },
   "outputs": [],
   "source": [
    "print('Unique item names after correction:', len(items['item_name'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "beb77fb09af07912061629ed55d3f47df33355e8"
   },
   "source": [
    "### Possible Item features:\n",
    "1. Item name\n",
    "2. Encoded aditional feature "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "66a0923b3fc90f074a272a5a13a61c551114464d"
   },
   "source": [
    "## 1.7 Category info\n",
    "* * *\n",
    "The structure here is\n",
    "### Section name - subsection\n",
    "we can split it and have two features from one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "79468132a8d99474a585d7bb6508115da7a1f965"
   },
   "outputs": [],
   "source": [
    "categories = pd.read_csv('../input/item_categories.csv')\n",
    "categories.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "511f796586cbffdf22586aa242cecf14b5469fb6"
   },
   "source": [
    "### But I did manual feature extraction here to have four features.\n",
    "Section / Main Category name / Main SubCategory name / Secondary SubCategory name\n",
    "#### Аксессуары / PS2\t/ PS / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "865d362d26204f248b5ad64fc4465601c0d2b82c"
   },
   "source": [
    "### Possible Category features\n",
    "1. Section\n",
    "2. Main Category name\n",
    "3. Main SubCategory name \n",
    "4. Secondary SubCategory name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1cd738638ec06398323532426cdd0473a8207e5e"
   },
   "source": [
    "## 1.8 Test Set\n",
    "* * *\n",
    "The key to my success was the analysis of Test test data.\n",
    "\n",
    "We have three groups of items:\n",
    "1. Item/shop pairs that are in train\n",
    "2. Items without any data\n",
    "3. Items that are in train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b841aa8e71c4327c1dc96237c6a9c4a7f872d8d3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('../input/test.csv')\n",
    "good_sales = test.merge(sale_train, on=['item_id','shop_id'], how='left').dropna()\n",
    "good_pairs = test[test['ID'].isin(good_sales['ID'])]\n",
    "no_data_items = test[~(test['item_id'].isin(sale_train['item_id']))]\n",
    "\n",
    "print('1. Number of good pairs:', len(good_pairs))\n",
    "print('2. No Data Items:', len(no_data_items))\n",
    "print('3. Only Item_id Info:', len(test)-len(no_data_items)-len(good_pairs))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bf3bba0a38999f2b15e10b0062cd84563c105832"
   },
   "source": [
    "#### Is it feature? Yes. We need to apply different prediction approach for each type of items in the test set.\n",
    "####  For example - \"No Data Items\" - it is more likely classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ef56ab0e5fc525bf4afb7554f08d2d775076e4d6"
   },
   "source": [
    "### Next part will be about data aggregation and feature preparation.\n",
    "## To be continued..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e5f615f0a8dd65504e38a77b3bca1b2ec1404b6c"
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
